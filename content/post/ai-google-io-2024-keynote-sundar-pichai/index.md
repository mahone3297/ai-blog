+++
title = '[AI Google] Google I/O 2024: 为新一代设计的 I/O'
date = 2024-05-31T15:40:33+08:00
draft = false
categories = ['AI', 'Google']
tags = ['AI', 'Google']
description = '探索 Google I/O 2024 的公告，重点介绍 AI 领域的创新和新的 Gemini 时代。了解 Gemini 模型如何变革搜索、照片和工作区等产品，并了解 AI 基础设施的最新进展。'
keywords = ['Google I/O 2024', 'AI', 'Google Gemini', '多模态 AI', '搜索中的 AI', 'Google 照片 AI', '工作区 AI', 'TPU Trillium', 'AI 基础设施']
+++

![Sundar 在舞台上，背景显示填充渐变色的 I / O 字母。](https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SP_Hero_Update_1.width-1200.format-webp.webp)

编辑注：以下是 Sundar Pichai 在 I/O 2024 上讲话的编辑版，并包含了更多在舞台上宣布的内容。查看我们收藏中的所有公告。

Google 完全进入了我们的 Gemini 时代。

在开始之前，我想反思一下我们所处的这一刻。我们已经在 AI 上投资了十多年，并在堆栈的每一层进行创新：研究、产品、基础设施，今天我们将谈论这一切。

尽管如此，我们仍处于 AI 平台转变的早期阶段。我们看到了前方的巨大机会，为创作者、开发者、初创企业，为每个人。推动这些机会的正是我们的 Gemini 时代。因此，让我们开始吧。

{{< youtube _fuimO6ErKI >}}

## Gemini 时代
一年前在 I/O 舞台上，我们首次分享了关于 Gemini 的计划：一个从一开始就设计为原生多模态的前沿模型，能够跨文本、图像、视频、代码等进行推理。这标志着将任何输入转化为任何输出的一个大步骤——为新一代设计的 “I/O”。

自那以后，我们推出了首批 Gemini 模型，这是我们迄今为止最强大的模型。它们在每个多模态基准上展示了最先进的性能。两个月后，我们推出了 Gemini 1.5 Pro，在长上下文方面取得了重大突破。它可以在生产中运行 100 万个标记，持续不断，比任何其他大规模基础模型都要多。

我们希望每个人都能受益于 Gemini 的功能。因此，我们迅速行动，将这些进展分享给大家。今天，超过 150 万开发者在我们的工具中使用 Gemini 模型。你们正在使用它来调试代码，获取新见解，并构建下一代 AI 应用程序。

我们还在我们的产品中以强大的方式引入了 Gemini 的突破性功能。今天我们将展示跨搜索、照片、工作区、Android 等的示例。

## 产品进展
今天，我们所有有 20 亿用户的产品都使用了 Gemini。

我们还推出了新的体验，包括在移动设备上，用户可以通过应用直接与 Gemini 互动，现在可以在 Android 和 iOS 上使用。通过 Gemini Advanced 提供访问我们最强大的模型。仅在三个月内就有超过 100 万人注册尝试，并且势头强劲。

## 扩展搜索中的 AI 概览
Gemini 在 Google 搜索中的转变是最令人兴奋的之一。

在过去的一年中，我们在搜索生成体验中回答了数十亿个查询。人们正在以全新的方式使用搜索，提出新类型的问题、更长和更复杂的查询，甚至用照片搜索，并获得网络上最好的内容。

{{< video "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/AI_Overviews_-_Sofa_qGYHf9J.mp4" >}}

我们一直在实验室外测试这一体验。我们很高兴看到不仅搜索使用量增加，用户满意度也提高了。

我很高兴地宣布，本周我们将在美国全面推出这款全新改版的体验 AI 概览。我们很快将其带到更多国家。

搜索中有很多创新正在发生。感谢 Gemini，我们可以创造更强大的搜索体验，包括在我们的产品内。

## 推出 Ask Photos
一个例子是我们在近九年前推出的 Google 照片。自那时起，人们使用它来组织他们最重要的记忆。今天，每天上传的照片和视频超过 60 亿张。

人们喜欢使用照片搜索他们的生活。通过 Gemini，我们使这一过程变得更加容易。

假设你在停车站付款，但记不住你的车牌号。以前，你可以搜索照片中的关键词，然后翻看多年的照片，寻找车牌号。现在，你可以直接问照片。它知道经常出现的车辆，能三角定位出哪辆是你的，并告诉你车牌号。

Ask Photos 还可以帮助你更深入地搜索记忆。例如，你可能想回忆你女儿 Lucia 的早期里程碑。现在，你可以问照片：“Lucia 什么时候学会游泳的？”

你还可以进一步问更复杂的问题：“展示 Lucia 的游泳进步。”

在这里，Gemini 超越了简单的搜索，能够识别不同的上下文——从在泳池中做圈，到在海洋中浮潜，到她游泳证书上的文本和日期。照片将这些信息打包在一起，以便你能真正体验，并重新回忆那些美好的记忆。我们将在今年夏天推出 Ask Photos，并会有更多功能。

![移动设备上的照片 UI，提示“展示 Lucia 的游泳进步。” 回应展示了一系列女孩在不同场景中游泳的照片。](https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ask-Photos_Phone-UI.width-1000.format-webp.webp)

## 解锁多模态和长上下文的更多知识
解锁跨格式的知识是我们从一开始就将 Gemini 构建为多模态的原因。这是一个模型，内置了所有的模态。因此，它不仅理解每种类型的输入，还能找到它们之间的联系。

多模态大大扩展了我们可以提出的问题和得到的答案。长上下文更进一步，使我们能够引入更多信息：数百页文本、数小时音频或一小时视频、整个代码库…或者，如果你愿意的话，大约 96 份 Cheesecake Factory 菜单。

对于这么多的菜单，你需要一个 100 万标记的上下文窗口，现在通过 Gemini 1.5 Pro 成为可能。开发者们以非常有趣的方式使用它。

{{< youtube cogrixfRvWw >}}

在过去几个月中，我们一直在预览中推出具有长上下文的 Gemini 1.5 Pro。我们在翻译、编码和推理方面进行了系列质量改进。从今天开始，你将看到这些更新反映在模型中。

现在我很高兴地宣布，我们正在将改进版的 Gemini 1.5 Pro 推广给全球所有开发者。此外，今天具有 100 万上下文的 Gemini 1.5 Pro 现在直接在 Gemini Advanced 中向消费者开放。这可以在 35 种语言中使用。

## 在私人预览中扩展到 200 万标记
100 万标记正在开创新的可能性。这很令人兴奋，但我认为我们可以进一步推动自己。

因此，今天，我们将上下文窗口扩展到 200 万标记，并在私人预览中向开发者开放。

回顾过去的几个月，看到我们取得了多大的进展，真是令人惊讶。这代表了我们在通向无限上下文的最终目标上的下一步。

## 将 Gemini 1.5 Pro 带入 Workspace
到目前为止，我们讨论了两项技术进步：多模态和长上下文。每个单独都非常强大。但结合起来，它们解锁了更深的能力和更多的智能。

这在 Google Workspace 中得以实现。

人们总是在 Gmail 中搜索邮件。我们正在努力通过 Gemini 使其更强大。例如，作为父母，你希望了解有关你孩子学校的一切。Gemini 可以帮助你保持跟进。

现在我们可以让 Gemini 总结来自学校的所有最新邮件。在后台，它正在识别相关邮件，甚至分析附件，如 PDF。你会得到要点和行动项的总结。也许你本周在旅行，无法参加家长教师会的会议。会议记录有一个小时长。如果是来自 Google Meet，你可以让 Gemini 给你一个亮点。家长小组正在寻找志愿者，而你那天有空。当然，Gemini 可以草拟回复。

还有无数其他例子可以说明这如何使生活更轻松。今天，Gemini 1.5 Pro 在 Workspace Labs 中可用。Aparna 分享更多内容。

## NotebookLM 中的音频输出
我们刚刚看了一个文本输出的例子。但通过多模态模型，我们可以做更多事情。

我们在这里取得了进展，还有更多内容即将到来。NotebookLM 中的音频概览展示了进展。它使用 Gemini 1.5 Pro 将你的素材生成个性化和互动的音频对话。

这就是多模态的机会。很快你就能混合和匹配输入和输出。这就是我们所说的为新一代设计的 I/O。但如果我们可以更进一步呢？

## 通过 AI 代理走得更远
进一步推进是我们在 AI 代理方面看到的机会。我把它们想象成展示推理、规划和记忆的智能系统。它们能够提前思考多步，并跨软件和系统工作，以代表你完成一些事情，最重要的是，在你的监督下进行。

我们仍处于早期阶段，但让我展示一下我们努力解决的用例类型。

让我们从购物开始。购买鞋子很有趣，但当它们不合适时退货就没那么有趣了。

想象一下，如果 Gemini 可以为你完成所有步骤：

搜索收件箱中的收据…

从你的电子邮件中找到订单号…

填写退货表格…

甚至安排 UPS 上门取件。

这样要容易得多，对吧？

让我们再看一个更复杂的例子。

假设你刚搬到芝加哥。你可以想象 Gemini 和 Chrome 一起帮助你做好准备——组织、推理、综合你的需求。

例如，你会想要探索这座城市，找到附近的服务——从干洗店到遛狗服务。你还需要在几十个网站上更新你的新地址。

Gemini 可以跨这些任务工作，并在需要时提示你提供更多信息——所以你始终掌控。

这一点非常重要——当我们设计这些体验时，我们正在认真思考如何以隐私、安全的方式进行，并适合所有人。

这些是简单的用例，但它们可以很好地展示我们希望通过构建智能系统来解决的问题类型，这些系统能够提前思考、推理和计划——所有这些都在你的代表下完成。

## 对我们的使命的意义
Gemini 的力量——具有多模态、长上下文和代理——使我们更接近我们的最终目标：使 AI 对每个人都有帮助。

我们认为这是我们在实现我们的使命方面取得最大进展的方法：组织世界的信息，跨越每个输入，使其通过任何输出都能访问，并将世界的信息与你的世界中的信息结合起来，以一种真正对你有用的方式。

## 开创未来
要实现 AI 的全部潜力，我们需要开创未来。Google DeepMind 团队一直在努力实现这一目标。

我们已经看到了对 1.5 Pro 和其长上下文窗口的巨大兴奋。但我们也听到了开发者的反馈，他们希望有更快、更具成本效益的解决方案。因此，明天，我们将推出 Gemini 1.5 Flash，一个为规模而构建的轻量级模型。它针对低延迟和成本至关重要的任务进行了优化。1.5 Flash 将于周二在 AI Studio 和 Vertex AI 上提供。

展望未来，我们一直希望构建一个在日常生活中有用的通用代理。Project Astra 展示了多模态理解和实时对话能力。

{{< youtube nXVvvRhiGjI >}}

我们还在视频和图像生成方面取得了进展，推出了 Veo 和 Imagen 3，并推出了 Gemma 2.0，我们的下一代开放模型，用于负责任的 AI 创新。阅读更多内容，请见 Demis Hassabis。

## AI 时代的基础设施：介绍 Trillium
训练最先进的模型需要大量的计算能力。过去六年中，ML 计算需求增长了 100 万倍。每年，它增加十倍。

Google 是为此而生的。25 年来，我们在世界级技术基础设施上进行了投资。从支持搜索的最先进硬件到支持我们 AI 进步的定制张量处理单元。

Gemini 完全在我们的第四和第五代 TPU 上进行了训练和服务。其他领先的 AI 公司，包括 Anthropic，也在 TPU 上训练了他们的模型。

今天，我们很高兴地宣布我们的第六代 TPU，名为 Trillium。Trillium 是我们迄今为止性能最强、效率最高的 TPU，相比上一代 TPU v5e 提供了 4.7 倍的计算性能提升。

我们将在 2024 年底向我们的云客户提供 Trillium。

除了我们的 TPU，我们还自豪地提供 CPU 和 GPU 以支持任何工作负载。这包括我们上个月宣布的新 Axion 处理器，这是我们首个定制的基于 Arm 的 CPU，提供业界领先的性能和能效。

我们还自豪地成为首批提供 Nvidia 的尖端 Blackwell GPU 的云提供商之一，将于 2025 年初提供。我们很幸运与 NVIDIA 有长期合作关系，并且很高兴将 Blackwell 的突破性能力带给我们的客户。

芯片是我们集成端到端系统的基础部分。从性能优化的硬件和开放软件到灵活的消费模式。这一切都汇集在我们的 AI 超级计算机中，这是一个开创性的超级计算机架构。

企业和开发者正在使用它来解决更复杂的挑战，其效率是购买原始硬件和芯片的两倍多。我们的 AI 超级计算机的进步部分归功于我们在数据中心液冷方面的方法。

我们已经这样做了近十年，远在它成为行业最先进的技术之前。今天，我们部署的液冷系统总容量接近 1 吉瓦，并且在不断增长——这是任何其他机队容量的 70 倍左右。

这一切的基础是我们全球连接基础设施的巨大规模。我们的网络覆盖了超过 200 万英里的陆地和海底光纤：是下一个领先的云提供商的 10 倍！

我们将继续进行必要的投资，以推动 AI 创新并提供最先进的能力。

{{< video "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/TPU_Timeline_Resized_2.mp4" >}}

## 搜索最激动人心的篇章
我们最大投资和创新领域之一是我们的创始产品——搜索。25 年前，我们创建搜索是为了帮助人们理解在线上不断涌动的信息浪潮。

随着每个平台的转变，我们不断提供突破，以更好地回答你的问题。在移动端，我们解锁了新类型的问题和答案——使用更好的上下文、位置感知和实时信息。随着自然语言理解和计算机视觉的进步，我们实现了新的搜索方式，通过声音、哼唱找到你最喜欢的新歌；或者通过你在散步时看到的花的图像进行搜索。现在，你甚至可以环绕搜索那些你可能想要购买的酷炫新鞋子。尽管如此，你可以随时退货！

当然，Gemini 时代的搜索将把这一切提升到一个全新的水平，结合我们的基础设施优势、最新的 AI 能力、我们对信息质量的高标准以及我们数十年连接你与丰富网络经验的经验。结果是一个为你工作的产品。

Google 搜索是符合人类好奇心规模的生成式 AI。这是我们搜索最激动人心的篇章。阅读 Liz Reid 关于 Gemini 时代搜索的更多内容。

## 更智能的 Gemini 体验
Gemini 不只是一个聊天机器人；它被设计为你的个人帮助助手，可以帮助你处理复杂任务并代表你采取行动。

与 Gemini 互动应该感觉对话和直观。因此，我们宣布了一种新的 Gemini 体验，叫做 Live，它允许你使用语音与 Gemini 进行深入对话。我们还将在今年晚些时候将 2M 标记带到 Gemini Advanced，使其能够上传和分析超密集文件，如视频和长代码。Sissie Hsiao 分享更多内容。

## Android 上的 Gemini
拥有全球数十亿 Android 用户，我们很高兴将 Gemini 更深地集成到用户体验中。作为你的新 AI 助手，Gemini 随时随地为你提供帮助。我们已经将 Gemini 模型集成到 Android 中，包括我们最新的设备模型：Gemini Nano with Multimodality，它处理文本、图像、音频和语音，解锁新体验，同时在设备上保持信息的私密性。Sameer Samat 分享 Android 的最新消息。

## 我们对 AI 的负责任态度
我们继续以大胆的态度迎接 AI 的机会，同时保持兴奋感。我们也确保我们负责任地进行。我们正在开发一种前沿技术，称为 AI 辅助红队，这借鉴了 Google DeepMind 在游戏突破中的 AlphaGo，以改进我们的模型。此外，我们已经扩展了 SynthID，我们的水印工具，使 AI 生成的内容更容易识别，扩展到两种新模式：文本和视频。James Manyika 分享更多内容。

## 共同创造未来
所有这些都展示了我们在采取大胆和负责任的方法使 AI 对每个人都有帮助方面的重要进展。

我们一直以来都采用 AI 优先的方法。我们数十年的研究领导力开创了许多现代突破，这些突破推动了 AI 的进步，对我们和整个行业都是如此。除此之外，我们还有：

- 为 AI 时代打造的世界领先的基础设施
- 由 Gemini 驱动的搜索中的尖端创新
- 以非凡的规模提供帮助的产品——包括 15 款拥有 5 亿用户的产品
- 以及使每个人——合作伙伴、客户、创作者和所有人——能够发明未来的平台。

这一进步仅因我们令人难以置信的开发者社区而成为可能。你们通过每天构建的体验和应用程序使这一切成为现实。因此，致所有在 Shoreline 的人以及世界各地数百万的观众，期待未来的可能性并共同创造它们。

---

- [原文](https://blog.google/inside-google/message-ceo/google-io-2024-keynote-sundar-pichai/)
- [博客 - 从零开始学AI](https://blog.aihub2022.top/post/ai-google-io-2024-keynote-sundar-pichai/)
- [公众号 - 从零开始学AI](https://mp.weixin.qq.com/s?__biz=MzA3MDIyNTgzNA==&mid=2649977307&idx=1&sn=d6b13ac7aa158cf8ca335f4192df45f6&chksm=86c7cb1eb1b04208d53ee288c9cb4ca9d61e934c924397bfcfa785a9e6f0232ac49522c822c2#rd)
<!-- - [CSDN - 从零开始学AI](...) -->
<!-- - [掘金 - 从零开始学AI](...) -->
<!-- - [知乎 - 从零开始学AI](...) -->
<!-- - [阿里云 - 从零开始学AI](...) -->
<!-- - [腾讯云 - 从零开始学AI](...) -->
