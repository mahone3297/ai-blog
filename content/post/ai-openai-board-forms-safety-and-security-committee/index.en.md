+++
title = '[AI OpenAI] OpenAI Board Forms Safety and Security Committee'
date = 2024-05-29T09:22:42+08:00
draft = false
categories = ['AI', 'OpenAI']
tags = ['AI', 'OpenAI']
description = 'The OpenAI Board has established a Safety and Security Committee to oversee critical decisions regarding the safety and security of OpenAI projects. The committee, led by directors Bret Taylor, Adam D’Angelo, Nicole Seligman, and CEO Sam Altman, is tasked with developing recommendations within 90 days.'
keywords = ['OpenAI', 'Safety and Security Committee', 'AI Safety', 'Security', 'Bret Taylor', 'Adam D’Angelo', 'Nicole Seligman', 'Sam Altman']
+++

This new committee is responsible for making recommendations on critical safety and security decisions for all OpenAI projects; recommendations in 90 days.

![Abstract painting with a blend of blue, pink, and green hues, resembling a landscape with a clear sky](https://images.ctfassets.net/kftzwdyauwt9/HQwS8tBhvdIHzdncUIASA/795b47369f81da3f303996ac21f48f2b/abstract-landscape.jpg?w=1920&q=90&fm=webp)

Today, the OpenAI Board formed a Safety and Security Committee led by directors Bret Taylor (Chair), Adam D’Angelo, Nicole Seligman, and Sam Altman (CEO). This committee will be responsible for making recommendations to the full Board on critical safety and security decisions for OpenAI projects and operations.

OpenAI has recently begun training its next frontier model and we anticipate the resulting systems to bring us to the next level of capabilities on our path to AGI. While we are proud to build and release models that are industry-leading on both capabilities and safety, we welcome a robust debate at this important moment.

A first task of the Safety and Security Committee will be to evaluate and further develop OpenAI’s processes and safeguards over the next 90 days. At the conclusion of the 90 days, the Safety and Security Committee will share their recommendations with the full Board. Following the full Board’s review, OpenAI will publicly share an update on adopted recommendations in a manner that is consistent with safety and security.

OpenAI technical and policy experts Aleksander Madry (Head of Preparedness), Lilian Weng (Head of Safety Systems), John Schulman (Head of Alignment Science), Matt Knight (Head of Security), and Jakub Pachocki (Chief Scientist) will also be on the committee.

Additionally, OpenAI will retain and consult with other safety, security, and technical experts to support this work, including former cybersecurity officials, Rob Joyce, who advises OpenAI on security, and John Carlin.

---

- [original](https://openai.com/index/openai-board-forms-safety-and-security-committee/)
- [Blog | Learn AI from scratch](https://blog.aihub2022.top/en/post/ai-openai-board-forms-safety-and-security-committee/)
<!-- - [CSDN - 从零开始学AI](...) -->
<!-- - [掘金 - 从零开始学AI](...) -->
<!-- - [知乎 - 从零开始学AI](...) -->
<!-- - [阿里云 - 从零开始学AI](...) -->
<!-- - [腾讯云 - 从零开始学AI](...) -->
