+++
title = '[AI OpenAI] 深入探讨语音引擎的工作原理和我们的安全研究'
date = 2024-06-09T10:31:49+08:00
draft = false
categories = ['AI', 'OpenAI']
tags = ['AI', 'OpenAI']
description = '了解OpenAI的语音引擎技术如何生成类似真人的语音，以及公司如何在研发中融入安全措施，确保技术的正面应用。'
keywords = ['AI', 'OpenAI', '语音引擎', '文本到语音', '安全研究']
+++

本文介绍了OpenAI开发的语音引擎的工作原理和安全研究。语音引擎是一个文本到语音(TTS)模型，能够仅从文本和15秒的样本语音中生成类似人类的音频。该模型通过理解配对音频和转录的语音细微差别进行开发，并能够生成反映不同类型说话者会如何说出它们的语音。OpenAI在2022年底首次开发了语音引擎，并进行了内部测试以评估其能力和局限性。此外，OpenAI还与政府、媒体、娱乐、教育等领域的合作伙伴进行交流，以确保在构建过程中纳入他们的反馈，并实施了多项安全措施。

---

探索我们文本到语音模型的技术。

![使用粉彩颜色混合的抽象画，包括粉色、橙色、紫色和绿色，类似于一个充满活力的景观。](https://images.ctfassets.net/kftzwdyauwt9/1F9YYY34lTeNq289xLAF6G/097bda3f5ef7b71943baada651f4b09f/abstract-pastel.jpg?w=1920&q=90&fm=webp)

我们正在提供更多关于语音引擎如何工作以及我们的安全研究的洞察，以保持每个人对我们进展的了解。语音引擎是一个能够创建定制声音的模型。

重要的是，全世界的人们理解这项技术的发展方向，无论我们最终是否自己广泛部署它。这就是为什么我们想解释模型是如何工作的，我们如何使用它进行研究和教育，以及我们如何围绕它实施我们的安全措施。语音引擎还没有广泛可用。

## 语音引擎的工作原理
语音功能由文本到语音（TTS）模型提供支持，该模型能够仅从文本和15秒的样本语音中生成类似人类的音频。

TTS系统是通过帮助模型理解配对音频和转录的语音细微差别来开发的。该模型学会了预测对于给定的文本转录，说话者最可能发出的声音，考虑到不同的声音、口音和说话风格。之后，TTS模型不仅可以生成文本的口语版本，还可以生成反映不同类型说话者会如何说出它们的语音。

从那里，使用TTS模型生成音频只需要说话者的15秒样本和相应的文本。该模型不是为任何特定说话者微调的，没有模型定制涉及。相反，它采用扩散过程，从随机噪声开始，逐步去噪，以密切匹配15秒音频样本中的说话者会如何表达文本。

## 我们开发这个模型已经超过一年了
我们在2022年底首次开发了语音引擎。早期，为了评估我们语音引擎模型的能力和局限性，我们使用公共和私人语音样本混合进行了内部测试。这个内部原型对于我们的对齐和安全研究至关重要，告知了我们的防护措施，并且是我们理解技术前沿的承诺的延续。

重要的是，这些输出仅用于内部测试，不用于训练我们产品所依赖的模型。

作为我们迭代部署框架的一部分，这个早期原型也在帮助政策制定者理解合成语音模型的能力方面发挥了宝贵作用。例如，从去年夏天开始，我们向全球最高级别的政策制定者展示了这项技术的潜力，并与他们讨论了相关风险。

在2023年9月，我们使用语音引擎为ChatGPT的语音模式功能提供支持。因为这些能力也带来了新的风险，我们仅为这个特定用例启动了它。语音模式完全由真实声音创建，通过一个从2023年5月开始的详细过程精心挑选，涉及专业配音演员、人才代理机构、选角导演和行业顾问。

在2023年11月，我们发布了一个简单的TTS API，也由语音引擎提供支持。我们选择了另一个有限发布，与专业配音演员合作，创建15秒音频样本，为API中的每个预设声音提供动力。开发人员可以将这些声音集成到他们的网站中，例如，大声朗读博客文章。

在今年3月，我们向一小部分受信任的合作伙伴预览了语音引擎创建定制声音的能力。这一举措旨在提高人们对合成声音能力的认识，并支持以下目标：

- 逐步淘汰基于声音的身份验证作为访问银行账户和其他敏感信息的安全措施
- 探索保护在人工智能中使用个人声音的政策
- 教育公众理解人工智能技术的能力和局限性，包括欺骗性AI内容的可能性
- 加速开发和采用追踪音视频内容来源的技术，以便总是清楚你是在与真人还是与AI互动

这些小规模部署也有助于告知我们的方法、防护措施以及关于如何将语音引擎用于各个行业的好处的思考。

## 安全地构建语音引擎是我们的首要任务
我们继续与美国和国际合作伙伴，包括政府、媒体、娱乐、教育、民间社会等领域的合作伙伴，进行交流，以确保我们在构建过程中纳入他们的反馈。

测试语音引擎的合作伙伴同意遵守使用政策，禁止未经同意的模仿，并要求原始说话者的明确批准，并要求任何AI生成的语音都必须向听众披露。此外，诸如水印和主动监控的安全措施已经到位，以追踪和监督技术的使用。

## 未来合成声音的安全
像GPT-4o这样的全能模型，具有原生音频能力，使得之前模型如语音引擎无法实现的新交互成为可能。我们也认识到GPT-4o的音频模式引入了几个新的风险，特别是在声音生成方面。我们正在积极地对GPT-4o进行红队测试，以识别和解决各个领域（如社会心理学、偏见和公平性、误信息）中已知和未知的风险。我们正在构建多层缓解措施，如改进模型行为、为GPT-4o的架构调整现有的基于文本的系统，以及开发新的分类器。

与我们谨慎发布语音引擎的方法一致，我们将限制GPT-4o的音频输出到一个预设声音的选择，供一般发布使用。这些声音来自通过仔细考虑的选角过程挑选的专业配音演员。我们将在即将发布的GPT-4o系统卡中分享有关音频相关风险和缓解措施的更多信息。

---

- [原文](https://openai.com/index/expanding-on-how-voice-engine-works-and-our-safety-research/)
<!-- - [AI 博客 - 从零开始学AI](...) -->
<!-- - [公众号 - 从零开始学AI](...) -->
<!-- - [CSDN - 从零开始学AI](...) -->
<!-- - [掘金 - 从零开始学AI](...) -->
<!-- - [知乎 - 从零开始学AI](...) -->
<!-- - [阿里云 - 从零开始学AI](...) -->
<!-- - [腾讯云 - 从零开始学AI](...) -->
